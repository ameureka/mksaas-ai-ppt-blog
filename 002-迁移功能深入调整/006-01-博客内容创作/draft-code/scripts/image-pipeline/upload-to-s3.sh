#!/bin/bash
# S3 ä¸Šä¼ è„šæœ¬
# ç”¨æ³•: bash scripts/image-pipeline/upload-to-s3.sh

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
COMPRESSED_DIR="$SCRIPT_DIR/../../compressed"
PUBLIC_DIR="$SCRIPT_DIR/../../../../public/images/blog"
DATA_DIR="$SCRIPT_DIR/../../data"
TASKS_FILE="$DATA_DIR/image-tasks.json"

# é¢œè‰²è¾“å‡º
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m'

echo -e "${GREEN}â˜ï¸ å›¾ç‰‡ä¸Šä¼ æµç¨‹${NC}"
echo "===================="
echo ""

# æ­¥éª¤ 1: å¤åˆ¶åˆ° public ç›®å½•
copy_to_public() {
  echo -e "${GREEN}ğŸ“ æ­¥éª¤ 1: å¤åˆ¶åˆ° public/images/blog/${NC}"

  mkdir -p "$PUBLIC_DIR"

  if [ ! -d "$COMPRESSED_DIR" ] || [ -z "$(ls -A "$COMPRESSED_DIR" 2>/dev/null)" ]; then
    echo -e "${YELLOW}âš ï¸ compressed ç›®å½•ä¸ºç©ºï¼Œå°è¯•ä» generated-images å¤åˆ¶${NC}"
    COMPRESSED_DIR="$SCRIPT_DIR/../../generated-images"
  fi

  if [ ! -d "$COMPRESSED_DIR" ] || [ -z "$(ls -A "$COMPRESSED_DIR" 2>/dev/null)" ]; then
    echo -e "${RED}âŒ æ²¡æœ‰å¯å¤åˆ¶çš„å›¾ç‰‡${NC}"
    return 1
  fi

  local count=0
  for img in "$COMPRESSED_DIR"/*.{jpg,jpeg,png,JPG,JPEG,PNG} 2>/dev/null; do
    [ -f "$img" ] || continue
    local filename=$(basename "$img")
    cp "$img" "$PUBLIC_DIR/$filename"
    count=$((count + 1))
  done

  echo "âœ… å·²å¤åˆ¶ $count ä¸ªæ–‡ä»¶åˆ° public/images/blog/"
  echo ""
}

# æ­¥éª¤ 2: ä¸Šä¼ åˆ° S3
upload_to_s3() {
  echo -e "${GREEN}â˜ï¸ æ­¥éª¤ 2: ä¸Šä¼ åˆ° S3${NC}"

  # æ£€æŸ¥ç¯å¢ƒå˜é‡
  if [ -z "$STORAGE_BUCKET_NAME" ]; then
    echo -e "${YELLOW}âš ï¸ STORAGE_BUCKET_NAME æœªè®¾ç½®${NC}"
    echo "è¯·åœ¨ .env.local ä¸­é…ç½® S3 ç›¸å…³ç¯å¢ƒå˜é‡"
    echo "è·³è¿‡ S3 ä¸Šä¼ ..."
    return 0
  fi

  if ! command -v aws &> /dev/null; then
    echo -e "${YELLOW}âš ï¸ AWS CLI æœªå®‰è£…${NC}"
    echo "å®‰è£…: brew install awscli"
    echo "è·³è¿‡ S3 ä¸Šä¼ ..."
    return 0
  fi

  local S3_BUCKET="$STORAGE_BUCKET_NAME"
  local S3_PREFIX="public/images/blog"

  echo "Bucket: $S3_BUCKET"
  echo "Prefix: $S3_PREFIX"
  echo ""

  # åŒæ­¥åˆ° S3
  aws s3 sync "$PUBLIC_DIR/" "s3://${S3_BUCKET}/${S3_PREFIX}/" \
    --acl public-read \
    --cache-control "max-age=31536000" \
    --exclude "*.DS_Store" \
    --exclude ".gitkeep"

  echo ""
  echo "âœ… S3 ä¸Šä¼ å®Œæˆ"
}

# æ­¥éª¤ 3: æ›´æ–°ä»»åŠ¡çŠ¶æ€
update_status() {
  echo -e "${GREEN}ğŸ“ æ­¥éª¤ 3: æ›´æ–°ä»»åŠ¡çŠ¶æ€${NC}"

  if [ ! -f "$TASKS_FILE" ]; then
    echo -e "${YELLOW}âš ï¸ ä»»åŠ¡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡çŠ¶æ€æ›´æ–°${NC}"
    return 0
  fi

  if ! command -v jq &> /dev/null; then
    echo -e "${YELLOW}âš ï¸ jq æœªå®‰è£…ï¼Œè·³è¿‡çŠ¶æ€æ›´æ–°${NC}"
    return 0
  fi

  local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

  # å°†æ‰€æœ‰ approved çŠ¶æ€æ›´æ–°ä¸º uploaded
  jq --arg ts "$timestamp" '
    .tasks |= map(
      if .cover.status == "approved" then .cover.status = "uploaded" | .cover.uploadedAt = $ts else . end |
      .inlineImages |= map(
        if .status == "approved" then .status = "uploaded" | .uploadedAt = $ts else . end
      ) |
      .updatedAt = $ts |
      # é‡æ–°è®¡ç®— mediaStatus
      if (.cover.status == "uploaded") and ([.inlineImages[] | select(.status == "uploaded")] | length >= 3)
      then .mediaStatus = "done"
      elif (.cover.status == "uploaded") or ([.inlineImages[] | select(.status == "uploaded")] | length > 0)
      then .mediaStatus = "partial"
      else .mediaStatus = "none"
      end
    )
  ' "$TASKS_FILE" > "$TASKS_FILE.tmp" && mv "$TASKS_FILE.tmp" "$TASKS_FILE"

  echo "âœ… çŠ¶æ€å·²æ›´æ–°"
}

# ä¸»å‡½æ•°
main() {
  copy_to_public
  upload_to_s3
  update_status

  echo ""
  echo -e "${GREEN}ğŸ‰ ä¸Šä¼ æµç¨‹å®Œæˆ${NC}"
  echo ""
  echo "ä¸‹ä¸€æ­¥:"
  echo "  1. è¿è¡Œ npx tsx scripts/image-pipeline/update-mdx.ts æ›´æ–° MDX æ–‡ä»¶"
  echo "  2. è¿è¡Œ npx tsx scripts/image-pipeline/show-progress.ts æŸ¥çœ‹è¿›åº¦"
}

main
